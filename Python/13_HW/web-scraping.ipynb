{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 1.\n",
    "Обязательная часть\n",
    "Будем парсить страницу со свежеми новостям на habr.com/ru/all/.\n",
    "\n",
    "Вам необходимо собирать только те статьи, в которых встречается хотя бы одно требуемое ключевое слово. Эти слова определяем в начале кода в переменной, например:\n",
    "\n",
    "KEYWORDS = ['python', 'парсинг']\n",
    "\n",
    "Поиск вести по всей доступной preview-информации (это информация, доступная непосредственно с текущей страницы).\n",
    "\n",
    "В итоге должен формироваться датафрейм вида: <дата> - <заголовок> - <ссылка>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KEYWORDS = ['python', 'парсинг', 'разработчик', 'ученые']\n",
    "\n",
    "res =  requests.get('https://habr.com/ru/all/')\n",
    "soup = BeautifulSoup(res.text, 'html.parser') \n",
    "links = soup.find_all('h2', class_='post__title')\n",
    "# извлечение всех тегов для ссылок\n",
    "link_list = list(map(lambda x: x.find('a').get('href'), links))\n",
    "# извлечение ссылок\n",
    "link_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_habr_news(link_list):\n",
    "    habr_news = pd.DataFrame()\n",
    "    for link in link_list:\n",
    "        soup = BeautifulSoup(requests.get(link).text, 'html.parser')\n",
    "#         запрос к ссылке\n",
    "        time.sleep(0.3)\n",
    "#     задержка на всякий случай\n",
    "        text = soup.find('div', class_ = 'post__body post__body_full').text.lower().strip()\n",
    "#     получение текста поста\n",
    "        for words in KEYWORDS:\n",
    "            if words in text:\n",
    "#                 поиск нужных слов\n",
    "                date = pd.to_datetime(soup.find('span', class_='post__time').get('data-time_published'), dayfirst = True).date()\n",
    "#     получение даты\n",
    "                title = soup.find('span', class_ = 'post__title-text').text\n",
    "#     получение загловка\n",
    "                row = {'date': date, 'title': title, 'link': link, 'text': text}\n",
    "                habr_news = pd.concat([habr_news, pd.DataFrame([row])])  \n",
    "#         склеивание в dataframe\n",
    "    return habr_news\n",
    "get_habr_news(link_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 2.\n",
    "Обязательная часть:\n",
    "\n",
    "Написать скрипт, который будет проверять список e-mail адресов на утечку при помощи сервиса Avast Hack Ckeck. Список email-ов задаем переменной в начале кода:\n",
    "EMAIL = [xxx@x.ru, yyy@y.com]\n",
    "\n",
    "В итоге должен формироваться датафрейм со столбцами: <дата утечки> - <источник утечки> - <описание утечки>\n",
    "\n",
    "Подсказка: сервис работает при помощи \"скрытого\" API. Внимательно изучите post-запросы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'emailAddresses': ['xxx@x.ru']}\n",
      "{'emailAddresses': ['yyy@y.com']}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>дата утечки</th>\n",
       "      <th>источник утечки</th>\n",
       "      <th>описание утечки</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-02-14T00:00:00Z</td>\n",
       "      <td>parapa.mail.ru</td>\n",
       "      <td>In July and August 2016, two criminals execute...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-10-29T00:00:00Z</td>\n",
       "      <td>vk.com</td>\n",
       "      <td>Popular Russian social networking platform VKo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-10-21T00:00:00Z</td>\n",
       "      <td>adobe.com</td>\n",
       "      <td>In October of 2013, criminals penetrated Adobe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-02-14T00:00:00Z</td>\n",
       "      <td>cfire.mail.ru</td>\n",
       "      <td>In July and August of 2016, two criminals carr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-01-31T00:00:00Z</td>\n",
       "      <td>cdprojektred.com</td>\n",
       "      <td>In March 2016, CDProjektRed.com.com's forum da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-10-23T00:00:00Z</td>\n",
       "      <td>imesh.com</td>\n",
       "      <td>In June 2016, a cache of over 51 million user ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-11-10T00:00:00Z</td>\n",
       "      <td>gamersoul.com</td>\n",
       "      <td>In May 2020, data belonging to the Bahamian-ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-03T00:00:00Z</td>\n",
       "      <td>azcentral.com</td>\n",
       "      <td>At an unconfirmed date, online Arizona newspap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-02-11T00:00:00Z</td>\n",
       "      <td>forums.vkmonline.com</td>\n",
       "      <td>At an unconfirmed date, the Russian-language m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-06-13T00:00:00Z</td>\n",
       "      <td>canva.com</td>\n",
       "      <td>In May 2019, graphic-design site Canva's datab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-10-24T00:00:00Z</td>\n",
       "      <td>dropbox.com</td>\n",
       "      <td>Cloud storage company Dropbox suffered a major...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-10-17T00:00:00Z</td>\n",
       "      <td>zynga.com</td>\n",
       "      <td>In September 2019, the game developer Zynga wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-10-21T00:00:00Z</td>\n",
       "      <td>adobe.com</td>\n",
       "      <td>In October of 2013, criminals penetrated Adobe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-02-18T00:00:00Z</td>\n",
       "      <td>netlog.com</td>\n",
       "      <td>Netlog (formerly known as Facebox and Bingbox)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-03-15T00:00:00Z</td>\n",
       "      <td>globalreach.eu</td>\n",
       "      <td>In 2016, Global Reach Technology's database wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-10-23T00:00:00Z</td>\n",
       "      <td>imesh.com</td>\n",
       "      <td>In June 2016, a cache of over 51 million user ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-03-24T00:00:00Z</td>\n",
       "      <td>youku.com</td>\n",
       "      <td>Youku is a large Chinese video content company...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-05-28T00:00:00Z</td>\n",
       "      <td>wishbone.io</td>\n",
       "      <td>In January 2020, the online poll website Wishb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-11-04T00:00:00Z</td>\n",
       "      <td>myheritage.com</td>\n",
       "      <td>In October 2017, a customer database belonging...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-10-21T00:00:00Z</td>\n",
       "      <td>linkedin.com</td>\n",
       "      <td>In 2012, online professional networking platfo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-03-01T00:00:00Z</td>\n",
       "      <td>rayli.com.cn</td>\n",
       "      <td>On an unconfirmed date, Chinese gossip site Ra...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            дата утечки       источник утечки  \\\n",
       "0  2017-02-14T00:00:00Z        parapa.mail.ru   \n",
       "0  2016-10-29T00:00:00Z                vk.com   \n",
       "0  2016-10-21T00:00:00Z             adobe.com   \n",
       "0  2017-02-14T00:00:00Z         cfire.mail.ru   \n",
       "0  2017-01-31T00:00:00Z      cdprojektred.com   \n",
       "0  2016-10-23T00:00:00Z             imesh.com   \n",
       "0  2022-11-10T00:00:00Z         gamersoul.com   \n",
       "0  2020-01-03T00:00:00Z         azcentral.com   \n",
       "0  2021-02-11T00:00:00Z  forums.vkmonline.com   \n",
       "0  2019-06-13T00:00:00Z             canva.com   \n",
       "0  2016-10-24T00:00:00Z           dropbox.com   \n",
       "0  2019-10-17T00:00:00Z             zynga.com   \n",
       "0  2016-10-21T00:00:00Z             adobe.com   \n",
       "0  2018-02-18T00:00:00Z            netlog.com   \n",
       "0  2017-03-15T00:00:00Z        globalreach.eu   \n",
       "0  2016-10-23T00:00:00Z             imesh.com   \n",
       "0  2017-03-24T00:00:00Z             youku.com   \n",
       "0  2020-05-28T00:00:00Z           wishbone.io   \n",
       "0  2017-11-04T00:00:00Z        myheritage.com   \n",
       "0  2016-10-21T00:00:00Z          linkedin.com   \n",
       "0  2017-03-01T00:00:00Z          rayli.com.cn   \n",
       "\n",
       "                                     описание утечки  \n",
       "0  In July and August 2016, two criminals execute...  \n",
       "0  Popular Russian social networking platform VKo...  \n",
       "0  In October of 2013, criminals penetrated Adobe...  \n",
       "0  In July and August of 2016, two criminals carr...  \n",
       "0  In March 2016, CDProjektRed.com.com's forum da...  \n",
       "0  In June 2016, a cache of over 51 million user ...  \n",
       "0  In May 2020, data belonging to the Bahamian-ba...  \n",
       "0  At an unconfirmed date, online Arizona newspap...  \n",
       "0  At an unconfirmed date, the Russian-language m...  \n",
       "0  In May 2019, graphic-design site Canva's datab...  \n",
       "0  Cloud storage company Dropbox suffered a major...  \n",
       "0  In September 2019, the game developer Zynga wa...  \n",
       "0  In October of 2013, criminals penetrated Adobe...  \n",
       "0  Netlog (formerly known as Facebox and Bingbox)...  \n",
       "0  In 2016, Global Reach Technology's database wa...  \n",
       "0  In June 2016, a cache of over 51 million user ...  \n",
       "0  Youku is a large Chinese video content company...  \n",
       "0  In January 2020, the online poll website Wishb...  \n",
       "0  In October 2017, a customer database belonging...  \n",
       "0  In 2012, online professional networking platfo...  \n",
       "0  On an unconfirmed date, Chinese gossip site Ra...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "URL = 'https://identityprotection.avast.com/v1/web/query/site-breaches/unauthorized-data'\n",
    "HEADERS = {\n",
    "    \n",
    "            'Accept-Encoding': 'gzip, deflate, br',\n",
    "            'Accept-Language': 'ru-RU,ru;q=0.9,pl-PL;q=0.8,pl;q=0.7,en-US;q=0.6,en;q=0.5',\n",
    "            'Connection': 'keep-alive',\n",
    "            'Content-Length': '31',\n",
    "            'Content-Type': 'application/json;charset=UTF-8',\n",
    "            'Host': 'identityprotection.avast.com',\n",
    "            'Origin': 'https://www.avast.com',\n",
    "            'Referer': 'https://www.avast.com/',\n",
    "            'sec-ch-ua': '\" Not;A Brand\";v=\"99\", \"Google Chrome\";v=\"91\", \"Chromium\";v=\"91\"',\n",
    "            'sec-ch-ua-mobile': '?0',\n",
    "            'Sec-Fetch-Dest': 'empty',\n",
    "            'Sec-Fetch-Mode': 'cors',\n",
    "            'Sec-Fetch-Site': 'same-site',\n",
    "            'User-Agent': 'Mozilla/4.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.114 Safari/537.36',\n",
    "            'Vaar-Header-App-Build-Version': '1.0.0',\n",
    "            'Vaar-Header-App-Product': 'hackcheck-web-avast',\n",
    "            'Vaar-Header-App-Product-Name': 'hackcheck-web-avast',\n",
    "            'Vaar-Version': '0'\n",
    "}\n",
    "EMAILS = {\n",
    "    'emailAddresses': ['xxx@x.ru']\n",
    "}\n",
    "EMAIL = ['xxx@x.ru','yyy@y.com']\n",
    "leaks_frame = pd.DataFrame()\n",
    "leaks_frame_new = pd.DataFrame()\n",
    "for i in range(len(EMAIL)):\n",
    "    EMAILS['emailAddresses'] = [EMAIL[i]]\n",
    "    print(EMAILS)\n",
    "    r = requests.post(URL, headers=HEADERS, json=EMAILS)\n",
    "    time.sleep(5)\n",
    "    #print(r)\n",
    "    respond = r.json()\n",
    "\n",
    "    for x in respond['breaches'].keys():\n",
    "        leaks_frame['дата утечки']= [respond['breaches'][x]['publishDate']] \n",
    "        leaks_frame['источник утечки']= [respond['breaches'][x]['site']] \n",
    "        leaks_frame['описание утечки']= [respond['breaches'][x]['description']]\n",
    "        leaks_frame_new = pd.concat([leaks_frame_new,leaks_frame])\n",
    "leaks_frame_new"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
