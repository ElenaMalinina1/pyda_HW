{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"14_Work with text 2.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyObr5FuPNHWxUUEkueDt7LX"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["## Задание\n","Реализуйте задачу машинного перевода с использованием transformer.\n"," [Датасет](http://www.manythings.org/anki/)"],"metadata":{"id":"iegLgH5-_4zn"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R6MkVFE6_P8n","executionInfo":{"status":"ok","timestamp":1661588300680,"user_tz":-180,"elapsed":2133,"user":{"displayName":"Vixen","userId":"12443801616054990678"}},"outputId":"3a159607-c3c2-4a00-b8bf-de888ddea508"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda')"]},"metadata":{},"execution_count":1}],"source":["from io import open\n","import unicodedata\n","import string\n","import re\n","import random\n","import math\n","import numpy as np\n","from collections import Counter\n","\n","import torch as tr\n","import torch.nn as nn\n","from torch import Tensor\n","from torch.nn import Transformer, TransformerEncoder, TransformerEncoderLayer\n","import torch.nn.functional as F\n","\n","from timeit import default_timer as timer\n","import time\n","\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","%matplotlib inline\n","\n","device = tr.device(\"cuda\" if tr.cuda.is_available() else \"cpu\") \n","device"]},{"cell_type":"code","source":["!wget https://www.manythings.org/anki/rus-eng.zip\n","!unzip rus-eng.zip"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VgOsVNEtGTcB","executionInfo":{"status":"ok","timestamp":1661588310622,"user_tz":-180,"elapsed":1981,"user":{"displayName":"Vixen","userId":"12443801616054990678"}},"outputId":"cec50378-2f0a-4386-e0ca-8b02c7c5c83d"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["--2022-08-27 08:18:30--  https://www.manythings.org/anki/rus-eng.zip\n","Resolving www.manythings.org (www.manythings.org)... 173.254.30.110\n","Connecting to www.manythings.org (www.manythings.org)|173.254.30.110|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 14819554 (14M) [application/zip]\n","Saving to: ‘rus-eng.zip’\n","\n","rus-eng.zip         100%[===================>]  14.13M  17.1MB/s    in 0.8s    \n","\n","2022-08-27 08:18:31 (17.1 MB/s) - ‘rus-eng.zip’ saved [14819554/14819554]\n","\n","Archive:  rus-eng.zip\n","  inflating: rus.txt                 \n","  inflating: _about.txt              \n"]}]},{"cell_type":"code","source":["SRC_LANGUAGE = 'eng'\n","TGT_LANGUAGE = 'rus'\n","\n","class Lang:\n","    def __init__(self, name):\n","        self.name = name\n","        self.word2index = {'<unk>': 0, '<pad>': 1, '<bos>': 2, '<eos>': 3}\n","        self.index2word = {0: '<unk>', 1: '<pad>', 2: '<bos>', 3: '<eos>'}\n","        self.word2count = {}\n","        self.n_words = 4 \n","\n","    def addSentence(self, sentence):\n","        for word in sentence:#.split(' '):\n","            self.addWord(word)\n","\n","    def addWord(self, word):\n","        if word not in self.word2index:\n","            self.word2index[word] = self.n_words\n","            self.word2count[word] = 1\n","            self.index2word[self.n_words] = word\n","            self.n_words += 1\n","        else:\n","            self.word2count[word] += 1"],"metadata":{"id":"EWScgghxGW4P","executionInfo":{"status":"ok","timestamp":1661588314598,"user_tz":-180,"elapsed":283,"user":{"displayName":"Vixen","userId":"12443801616054990678"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["def unicodeToAscii(s):\n","    return ''.join(c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn')\n","\n","def normalizeString(s):\n","    s = unicodeToAscii(s.lower().strip())\n","    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n","    s = re.sub(r\"[^a-zA-Zа-яА-ЯёЁ.!?]+\", r\" \", s)\n","    return s"],"metadata":{"id":"UX0GjlxWGZoU","executionInfo":{"status":"ok","timestamp":1661588316849,"user_tz":-180,"elapsed":318,"user":{"displayName":"Vixen","userId":"12443801616054990678"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["def readLangs(s_limit):\n","    print(\"Reading lines...\")\n","    lines = open('rus.txt', encoding='utf-8').read().strip().split('\\n')\n","    pairs = [[normalizeString(s) for s in re.split('\\t', l)] for l in lines]\n","    pairs_list = []\n","    for string in pairs:\n","        eng_split =  [i for i in re.split('[\\.!?]', string[0]) if i != '']\n","        esp_split =  [i for i in re.split('[\\.!?]', string[1]) if i != '']    \n","        if len(eng_split) ==  len(esp_split):\n","            for i in range(len(eng_split)):            \n","                eng_s = re.findall('[\\w]+', eng_split[i])[:s_limit]\n","                esp_s = re.findall('[\\w]+', esp_split[i])[:s_limit]\n","                pairs_list.append([eng_s, esp_s]) \n","    return pairs_list"],"metadata":{"id":"kMOx0JPxGa2_","executionInfo":{"status":"ok","timestamp":1661588342004,"user_tz":-180,"elapsed":287,"user":{"displayName":"Vixen","userId":"12443801616054990678"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["def prepareData(i_lang, o_lang, se_limit):\n","    pairs = readLangs(se_limit)\n","    inp_lang  = Lang(i_lang)\n","    out_lang  = Lang(o_lang)\n","    print(\"Read %s sentence pairs\" % len(pairs))\n","    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n","    print(\"Counting words...\")\n","    for pair in pairs:\n","        inp_lang.addSentence(pair[0])\n","        out_lang.addSentence(pair[1])\n","    print(\"Counted words:\")\n","    print(inp_lang.name, inp_lang.n_words)\n","    print(out_lang.name, out_lang.n_words)\n","    return inp_lang, out_lang, pairs"],"metadata":{"id":"wRPLgrbnGdh8","executionInfo":{"status":"ok","timestamp":1661588342981,"user_tz":-180,"elapsed":1,"user":{"displayName":"Vixen","userId":"12443801616054990678"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["def Prepare_Filt_Data(im_lang = SRC_LANGUAGE, ou_lang = TGT_LANGUAGE, \n","                      sen_limit = 20,  w_limit = 5):\n","    i1_lang, o1_lang, pairs=prepareData(im_lang, ou_lang, sen_limit)\n","    inp_lang_  = Lang(im_lang)\n","    out_lang_  = Lang(ou_lang)\n","\n","    eng_words_select = set([i for i in i1_lang.word2count.keys() \n","                               if i1_lang.word2count[i] > w_limit])\n","    esp_words_select = set([i for i in o1_lang.word2count.keys() \n","                               if o1_lang.word2count[i] > w_limit])\n","    \n","    for pair in pairs:\n","        for wrd_i in pair[0]:\n","            if wrd_i in eng_words_select:\n","                inp_lang_.addWord(wrd_i)\n","        for wrd_o in pair[1]:\n","            if wrd_o in esp_words_select:\n","                out_lang_.addWord(wrd_o)\n","\n","    print('Using filter: every dict word in sentenses > ', w_limit)\n","    print(inp_lang_.name, inp_lang_.n_words)\n","    print(out_lang_.name, out_lang_.n_words)\n","\n","    pairs_select = []\n","    for i in range(len(pairs)):\n","        if all(word in eng_words_select for word in pairs[i][0]):\n","            if all(word in esp_words_select for word in pairs[i][1]):\n","                   pairs_select.append([pairs[i][0], pairs[i][1]]) \n","\n","    print(len(pairs_select), 'sentenses')\n","    return inp_lang_, out_lang_, pairs_select"],"metadata":{"id":"TJ__LgqiQb3p","executionInfo":{"status":"ok","timestamp":1661588343961,"user_tz":-180,"elapsed":3,"user":{"displayName":"Vixen","userId":"12443801616054990678"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["input_lang, output_lang, pairs = Prepare_Filt_Data(sen_limit = 20, w_limit   = 5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JlA9tjdDT_Jf","executionInfo":{"status":"ok","timestamp":1661588387298,"user_tz":-180,"elapsed":42271,"user":{"displayName":"Vixen","userId":"12443801616054990678"}},"outputId":"e10162ed-49dc-4ff5-cb57-b54f567caffd"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Reading lines...\n","Read 446069 sentence pairs\n","Trimmed to 446069 sentence pairs\n","Counting words...\n","Counted words:\n","eng 16569\n","rus 56210\n","Using filter: every dict word in sentenses >  5\n","eng 7050\n","rus 16041\n","379269  sentenses\n"]}]},{"cell_type":"code","source":["full_len = len(pairs)\n","train_list = list(range(full_len))\n","random.shuffle(train_list)"],"metadata":{"id":"eZxWt6TlUb16","executionInfo":{"status":"ok","timestamp":1661588395947,"user_tz":-180,"elapsed":708,"user":{"displayName":"Vixen","userId":"12443801616054990678"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["MAX_LENGTH = 22\n","\n","def sent_to_torch(sent_in, l):\n","    sent_for_torch = np.zeros((MAX_LENGTH))\n","    for b in range(len(sent_in) + 2):\n","        if b == 0:\n","            sent_for_torch[b] = 2\n","        elif b <= len(sent_in):\n","            sent_for_torch[b] = l.word2index[sent_in[b-1]]\n","        elif (b==len(sent_in) + 1 and b <= MAX_LENGTH) or b == MAX_LENGTH+1:\n","            sent_for_torch[b] = 3\n","    return sent_for_torch"],"metadata":{"id":"tGu4MiYoGcJE","executionInfo":{"status":"ok","timestamp":1661588397603,"user_tz":-180,"elapsed":2,"user":{"displayName":"Vixen","userId":"12443801616054990678"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["def torch_to_sent(sent_tens, l):\n","  sentence = [l.index2word(i) for i in sent_tens if i  > 3]\n","  return ' '.join(sentence)"],"metadata":{"id":"2IIs9rskbdT4","executionInfo":{"status":"ok","timestamp":1661588401628,"user_tz":-180,"elapsed":259,"user":{"displayName":"Vixen","userId":"12443801616054990678"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["def get_batch(pairs_num_list, batch_size):\n","  batch_list = random.sample(pairs_num_list, batch_size)\n","\n","  s_np_in  = np.zeros((22))\n","  s_np_out = np.zeros((22))\n","\n","  for a in range(batch_size):\n","    sent_in = pairs[batch_list[a]][0]\n","    sent_in = sent_to_torch(sent_in, input_lang)\n","    s_np_in = np.vstack([s_np_in, sent_in])\n","       \n","    sent_out = pairs[batch_list[a]][1]\n","    sent_out = sent_to_torch(sent_out, output_lang)\n","    s_np_out = np.vstack([s_np_out, sent_out])\n","\n","  data   = tr.tensor( s_np_in[1:], dtype=tr.long, device=device).view(-1, batch_size)\n","  target = tr.tensor(s_np_out[1:], dtype=tr.long, device=device).view(-1)\n","\n","  return data, target"],"metadata":{"id":"IY_4JnrZb4nJ","executionInfo":{"status":"ok","timestamp":1661588403418,"user_tz":-180,"elapsed":292,"user":{"displayName":"Vixen","userId":"12443801616054990678"}}},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":["## Transformer"],"metadata":{"id":"-CBbMg_9eOaY"}},{"cell_type":"code","source":["class TransformerModel(nn.Module):\n","\n","    def __init__(self, n_token_in, n_token_out, ninp, nhead, nhid, nlayers, dropout=0.5):\n","        super(TransformerModel, self).__init__()\n","\n","        self.model_type = 'Transformer'\n","        self.src_mask = None\n","        self.pos_encoder = PositionalEncoding(ninp, dropout)\n","        encoder_layers = TransformerEncoderLayer(ninp, nhead, nhid, dropout)\n","        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n","        self.encoder = nn.Embedding(n_token_in, ninp)\n","        self.ninp = ninp\n","        self.decoder = nn.Linear(ninp, n_token_out)\n","\n","        self.init_weights()\n","\n","    def _generate_square_subsequent_mask(self, sz):\n","        mask = (tr.triu(tr.ones(sz, sz)) == 1).transpose(0, 1)\n","        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n","        return mask\n","\n","    def init_weights(self):\n","        initrange = 0.1\n","        self.encoder.weight.data.uniform_(-initrange, initrange)\n","        self.decoder.bias.data.zero_()\n","        self.decoder.weight.data.uniform_(-initrange, initrange)\n","\n","    def forward(self, src):\n","        if self.src_mask is None or self.src_mask.size(0) != len(src):\n","            device = src.device\n","            mask = self._generate_square_subsequent_mask(len(src)).to(device)\n","            self.src_mask = mask\n","\n","        src = self.encoder(src) * math.sqrt(self.ninp)\n","        src = self.pos_encoder(src)\n","        output = self.transformer_encoder(src, self.src_mask)\n","        output = self.decoder(output)\n","        return output"],"metadata":{"id":"0jgQHzoWchQs","executionInfo":{"status":"ok","timestamp":1661588405259,"user_tz":-180,"elapsed":258,"user":{"displayName":"Vixen","userId":"12443801616054990678"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["class PositionalEncoding(nn.Module):\n","\n","    def __init__(self, d_model, dropout=0.1, max_len=5000):\n","        super(PositionalEncoding, self).__init__()\n","        self.dropout = nn.Dropout(p=dropout)\n","\n","        pe = tr.zeros(max_len, d_model)\n","        position = tr.arange(0, max_len, dtype=tr.float).unsqueeze(1)\n","        div_term = tr.exp(tr.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n","        pe[:, 0::2] = tr.sin(position * div_term)\n","        pe[:, 1::2] = tr.cos(position * div_term)\n","        pe = pe.unsqueeze(0).transpose(0, 1)\n","        self.register_buffer('pe', pe)\n","\n","    def forward(self, x):\n","        x = x + self.pe[:x.size(0), :]\n","        return self.dropout(x)"],"metadata":{"id":"gyvnJQPVdMoQ","executionInfo":{"status":"ok","timestamp":1661588408617,"user_tz":-180,"elapsed":263,"user":{"displayName":"Vixen","userId":"12443801616054990678"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["n_tokens_in = input_lang.n_words\n","n_tokens_out= output_lang.n_words"],"metadata":{"id":"B2oKHnd0djY5","executionInfo":{"status":"ok","timestamp":1661588410463,"user_tz":-180,"elapsed":258,"user":{"displayName":"Vixen","userId":"12443801616054990678"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["emsize = 200   \n","nhid = 200    \n","nlayers = 2     \n","nhead = 2    \n","dropout = 0.5 \n","model = TransformerModel(n_tokens_in, n_tokens_out, emsize, nhead, nhid, nlayers, dropout).to(device)"],"metadata":{"id":"FN0zySRLKJ9f","executionInfo":{"status":"ok","timestamp":1661588416060,"user_tz":-180,"elapsed":4301,"user":{"displayName":"Vixen","userId":"12443801616054990678"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["criterion = nn.CrossEntropyLoss()\n","lr = 5  \n","optimizer = tr.optim.SGD(model.parameters(), lr=lr)\n","scheduler = tr.optim.lr_scheduler.StepLR(optimizer, 3.0, gamma=0.8)\n","batch_size = 50\n","range_step = 150\n","\n","def train():\n","  model.train()\n","  total_loss = 0.\n","  start_time = time.time()\n","  ntokens = n_tokens_out\n","  for i in range(range_step):\n","    data, targets = get_batch(train_list, batch_size)\n","    optimizer.zero_grad()\n","    output = model(data)\n","    loss = criterion(output.view(-1, ntokens), targets)\n","    loss.backward()\n","    tr.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n","    optimizer.step()\n","\n","    total_loss += loss.item()\n","        \n","    if i in range(1, range_step, 20) and i > 0:\n","      cur_loss = total_loss /i\n","      elapsed = time.time() - start_time\n","      print(f'| epoch {epoch:3d} | lr { scheduler.get_last_lr()[0]:02.2f} | loss {cur_loss:5.6f} | ppl { math.exp(cur_loss):8.6f}')\n","    \n","  return total_loss / range_step, model"],"metadata":{"id":"JXK4s0A5Orzk","executionInfo":{"status":"ok","timestamp":1661588545298,"user_tz":-180,"elapsed":265,"user":{"displayName":"Vixen","userId":"12443801616054990678"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["best_val_loss = float(\"inf\")\n","epochs = 20\n","best_model = None\n","\n","for epoch in range(1, epochs + 1):\n","  epoch_start_time = time.time()\n","  t_loss, model_   = train()\n","  print('-' * 55)\n","  print(f'|mean loss epoch   {epoch:3}|mean l {t_loss:5.6f}|vppl { math.exp(t_loss):4.6f}')\n","  print('-' * 55)\n","\n","  if t_loss < best_val_loss:\n","      best_val_loss = t_loss\n","      best_model = model_\n","\n","  scheduler.step()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vgk8X4Wyd_Ci","executionInfo":{"status":"ok","timestamp":1661588814259,"user_tz":-180,"elapsed":44251,"user":{"displayName":"Vixen","userId":"12443801616054990678"}},"outputId":"76f8a60e-8e0d-4c6b-b0a9-b1bfcb1a811b"},"execution_count":39,"outputs":[{"output_type":"stream","name":"stdout","text":["| epoch   1 | lr 0.02 | loss 3.026301 | ppl 20.620815\n","| epoch   1 | lr 0.02 | loss 1.558009 | ppl 4.749357\n","| epoch   1 | lr 0.02 | loss 1.542652 | ppl 4.676975\n","| epoch   1 | lr 0.02 | loss 1.530898 | ppl 4.622326\n","| epoch   1 | lr 0.02 | loss 1.520751 | ppl 4.575662\n","| epoch   1 | lr 0.02 | loss 1.517427 | ppl 4.560475\n","| epoch   1 | lr 0.02 | loss 1.516093 | ppl 4.554396\n","| epoch   1 | lr 0.02 | loss 1.516448 | ppl 4.556014\n","-------------------------------------------------------\n","|mean loss epoch     1|mean l 1.504124|vppl 4.500210\n","-------------------------------------------------------\n","| epoch   2 | lr 0.02 | loss 3.138358 | ppl 23.065961\n","| epoch   2 | lr 0.02 | loss 1.579426 | ppl 4.852169\n","| epoch   2 | lr 0.02 | loss 1.534810 | ppl 4.640444\n","| epoch   2 | lr 0.02 | loss 1.534148 | ppl 4.637373\n","| epoch   2 | lr 0.02 | loss 1.539529 | ppl 4.662393\n","| epoch   2 | lr 0.02 | loss 1.538313 | ppl 4.656727\n","| epoch   2 | lr 0.02 | loss 1.537180 | ppl 4.651454\n","| epoch   2 | lr 0.02 | loss 1.531871 | ppl 4.626826\n","-------------------------------------------------------\n","|mean loss epoch     2|mean l 1.522518|vppl 4.583754\n","-------------------------------------------------------\n","| epoch   3 | lr 0.02 | loss 2.966616 | ppl 19.426069\n","| epoch   3 | lr 0.02 | loss 1.550640 | ppl 4.714485\n","| epoch   3 | lr 0.02 | loss 1.523562 | ppl 4.588540\n","| epoch   3 | lr 0.02 | loss 1.509922 | ppl 4.526379\n","| epoch   3 | lr 0.02 | loss 1.502959 | ppl 4.494970\n","| epoch   3 | lr 0.02 | loss 1.509146 | ppl 4.522864\n","| epoch   3 | lr 0.02 | loss 1.506178 | ppl 4.509463\n","| epoch   3 | lr 0.02 | loss 1.505882 | ppl 4.508128\n","-------------------------------------------------------\n","|mean loss epoch     3|mean l 1.494540|vppl 4.457287\n","-------------------------------------------------------\n","| epoch   4 | lr 0.02 | loss 2.904558 | ppl 18.257171\n","| epoch   4 | lr 0.02 | loss 1.568868 | ppl 4.801211\n","| epoch   4 | lr 0.02 | loss 1.532743 | ppl 4.630860\n","| epoch   4 | lr 0.02 | loss 1.518459 | ppl 4.565184\n","| epoch   4 | lr 0.02 | loss 1.514671 | ppl 4.547923\n","| epoch   4 | lr 0.02 | loss 1.508764 | ppl 4.521141\n","| epoch   4 | lr 0.02 | loss 1.508125 | ppl 4.518250\n","| epoch   4 | lr 0.02 | loss 1.505827 | ppl 4.507878\n","-------------------------------------------------------\n","|mean loss epoch     4|mean l 1.496733|vppl 4.467070\n","-------------------------------------------------------\n","| epoch   5 | lr 0.02 | loss 3.066029 | ppl 21.456528\n","| epoch   5 | lr 0.02 | loss 1.582717 | ppl 4.868167\n","| epoch   5 | lr 0.02 | loss 1.544370 | ppl 4.685019\n","| epoch   5 | lr 0.02 | loss 1.524033 | ppl 4.590703\n","| epoch   5 | lr 0.02 | loss 1.521315 | ppl 4.578243\n","| epoch   5 | lr 0.02 | loss 1.511831 | ppl 4.535028\n","| epoch   5 | lr 0.02 | loss 1.513113 | ppl 4.540843\n","| epoch   5 | lr 0.02 | loss 1.511181 | ppl 4.532082\n","-------------------------------------------------------\n","|mean loss epoch     5|mean l 1.500459|vppl 4.483745\n","-------------------------------------------------------\n","| epoch   6 | lr 0.02 | loss 2.883165 | ppl 17.870747\n","| epoch   6 | lr 0.02 | loss 1.575944 | ppl 4.835304\n","| epoch   6 | lr 0.02 | loss 1.542464 | ppl 4.676096\n","| epoch   6 | lr 0.02 | loss 1.519214 | ppl 4.568631\n","| epoch   6 | lr 0.02 | loss 1.516460 | ppl 4.556068\n","| epoch   6 | lr 0.02 | loss 1.515337 | ppl 4.550954\n","| epoch   6 | lr 0.02 | loss 1.507022 | ppl 4.513271\n","| epoch   6 | lr 0.02 | loss 1.506061 | ppl 4.508935\n","-------------------------------------------------------\n","|mean loss epoch     6|mean l 1.497737|vppl 4.471558\n","-------------------------------------------------------\n","| epoch   7 | lr 0.01 | loss 3.002156 | ppl 20.128891\n","| epoch   7 | lr 0.01 | loss 1.587086 | ppl 4.889482\n","| epoch   7 | lr 0.01 | loss 1.537387 | ppl 4.652420\n","| epoch   7 | lr 0.01 | loss 1.531124 | ppl 4.623370\n","| epoch   7 | lr 0.01 | loss 1.530289 | ppl 4.619513\n","| epoch   7 | lr 0.01 | loss 1.513332 | ppl 4.541837\n","| epoch   7 | lr 0.01 | loss 1.512974 | ppl 4.540213\n","| epoch   7 | lr 0.01 | loss 1.508026 | ppl 4.517803\n","-------------------------------------------------------\n","|mean loss epoch     7|mean l 1.496726|vppl 4.467042\n","-------------------------------------------------------\n","| epoch   8 | lr 0.01 | loss 2.966531 | ppl 19.424422\n","| epoch   8 | lr 0.01 | loss 1.560484 | ppl 4.761125\n","| epoch   8 | lr 0.01 | loss 1.531694 | ppl 4.626006\n","| epoch   8 | lr 0.01 | loss 1.521525 | ppl 4.579203\n","| epoch   8 | lr 0.01 | loss 1.513934 | ppl 4.544573\n","| epoch   8 | lr 0.01 | loss 1.511405 | ppl 4.533096\n","| epoch   8 | lr 0.01 | loss 1.509658 | ppl 4.525184\n","| epoch   8 | lr 0.01 | loss 1.507237 | ppl 4.514243\n","-------------------------------------------------------\n","|mean loss epoch     8|mean l 1.495783|vppl 4.462829\n","-------------------------------------------------------\n","| epoch   9 | lr 0.01 | loss 3.046587 | ppl 21.043400\n","| epoch   9 | lr 0.01 | loss 1.585356 | ppl 4.881029\n","| epoch   9 | lr 0.01 | loss 1.540174 | ppl 4.665402\n","| epoch   9 | lr 0.01 | loss 1.527536 | ppl 4.606813\n","| epoch   9 | lr 0.01 | loss 1.520819 | ppl 4.575970\n","| epoch   9 | lr 0.01 | loss 1.516190 | ppl 4.554840\n","| epoch   9 | lr 0.01 | loss 1.507937 | ppl 4.517401\n","| epoch   9 | lr 0.01 | loss 1.504478 | ppl 4.501801\n","-------------------------------------------------------\n","|mean loss epoch     9|mean l 1.492697|vppl 4.449080\n","-------------------------------------------------------\n","| epoch  10 | lr 0.01 | loss 3.005590 | ppl 20.198136\n","| epoch  10 | lr 0.01 | loss 1.559879 | ppl 4.758246\n","| epoch  10 | lr 0.01 | loss 1.539261 | ppl 4.661146\n","| epoch  10 | lr 0.01 | loss 1.535567 | ppl 4.643958\n","| epoch  10 | lr 0.01 | loss 1.526343 | ppl 4.601320\n","| epoch  10 | lr 0.01 | loss 1.520352 | ppl 4.573836\n","| epoch  10 | lr 0.01 | loss 1.522290 | ppl 4.582706\n","| epoch  10 | lr 0.01 | loss 1.519962 | ppl 4.572050\n","-------------------------------------------------------\n","|mean loss epoch    10|mean l 1.508144|vppl 4.518338\n","-------------------------------------------------------\n","| epoch  11 | lr 0.01 | loss 3.179764 | ppl 24.041077\n","| epoch  11 | lr 0.01 | loss 1.594151 | ppl 4.924148\n","| epoch  11 | lr 0.01 | loss 1.554665 | ppl 4.733499\n","| epoch  11 | lr 0.01 | loss 1.538334 | ppl 4.656825\n","| epoch  11 | lr 0.01 | loss 1.532519 | ppl 4.629826\n","| epoch  11 | lr 0.01 | loss 1.521436 | ppl 4.578796\n","| epoch  11 | lr 0.01 | loss 1.519657 | ppl 4.570657\n","| epoch  11 | lr 0.01 | loss 1.520432 | ppl 4.574199\n","-------------------------------------------------------\n","|mean loss epoch    11|mean l 1.508708|vppl 4.520886\n","-------------------------------------------------------\n","| epoch  12 | lr 0.01 | loss 3.058647 | ppl 21.298729\n","| epoch  12 | lr 0.01 | loss 1.579317 | ppl 4.851642\n","| epoch  12 | lr 0.01 | loss 1.540174 | ppl 4.665402\n","| epoch  12 | lr 0.01 | loss 1.530936 | ppl 4.622500\n","| epoch  12 | lr 0.01 | loss 1.522234 | ppl 4.582451\n","| epoch  12 | lr 0.01 | loss 1.512367 | ppl 4.537460\n","| epoch  12 | lr 0.01 | loss 1.518790 | ppl 4.566694\n","| epoch  12 | lr 0.01 | loss 1.514323 | ppl 4.546344\n","-------------------------------------------------------\n","|mean loss epoch    12|mean l 1.501059|vppl 4.486439\n","-------------------------------------------------------\n","| epoch  13 | lr 0.01 | loss 3.061466 | ppl 21.358853\n","| epoch  13 | lr 0.01 | loss 1.577025 | ppl 4.840536\n","| epoch  13 | lr 0.01 | loss 1.517924 | ppl 4.562743\n","| epoch  13 | lr 0.01 | loss 1.512066 | ppl 4.536093\n","| epoch  13 | lr 0.01 | loss 1.510973 | ppl 4.531137\n","| epoch  13 | lr 0.01 | loss 1.509003 | ppl 4.522222\n","| epoch  13 | lr 0.01 | loss 1.513515 | ppl 4.542672\n","| epoch  13 | lr 0.01 | loss 1.512802 | ppl 4.539432\n","-------------------------------------------------------\n","|mean loss epoch    13|mean l 1.501294|vppl 4.487493\n","-------------------------------------------------------\n","| epoch  14 | lr 0.01 | loss 3.009830 | ppl 20.283959\n","| epoch  14 | lr 0.01 | loss 1.538518 | ppl 4.657683\n","| epoch  14 | lr 0.01 | loss 1.524700 | ppl 4.593763\n","| epoch  14 | lr 0.01 | loss 1.511082 | ppl 4.531633\n","| epoch  14 | lr 0.01 | loss 1.501000 | ppl 4.486171\n","| epoch  14 | lr 0.01 | loss 1.507338 | ppl 4.514695\n","| epoch  14 | lr 0.01 | loss 1.499360 | ppl 4.478822\n","| epoch  14 | lr 0.01 | loss 1.498629 | ppl 4.475549\n","-------------------------------------------------------\n","|mean loss epoch    14|mean l 1.490630|vppl 4.439892\n","-------------------------------------------------------\n","| epoch  15 | lr 0.01 | loss 3.015083 | ppl 20.390790\n","| epoch  15 | lr 0.01 | loss 1.604485 | ppl 4.975298\n","| epoch  15 | lr 0.01 | loss 1.535503 | ppl 4.643660\n","| epoch  15 | lr 0.01 | loss 1.541417 | ppl 4.671202\n","| epoch  15 | lr 0.01 | loss 1.522520 | ppl 4.583763\n","| epoch  15 | lr 0.01 | loss 1.517209 | ppl 4.559480\n","| epoch  15 | lr 0.01 | loss 1.510734 | ppl 4.530057\n","| epoch  15 | lr 0.01 | loss 1.510106 | ppl 4.527209\n","-------------------------------------------------------\n","|mean loss epoch    15|mean l 1.500841|vppl 4.485459\n","-------------------------------------------------------\n","| epoch  16 | lr 0.01 | loss 3.125318 | ppl 22.767138\n","| epoch  16 | lr 0.01 | loss 1.545600 | ppl 4.690783\n","| epoch  16 | lr 0.01 | loss 1.516012 | ppl 4.554027\n","| epoch  16 | lr 0.01 | loss 1.506374 | ppl 4.510348\n","| epoch  16 | lr 0.01 | loss 1.508325 | ppl 4.519154\n","| epoch  16 | lr 0.01 | loss 1.499624 | ppl 4.480004\n","| epoch  16 | lr 0.01 | loss 1.497270 | ppl 4.469470\n","| epoch  16 | lr 0.01 | loss 1.498238 | ppl 4.473801\n","-------------------------------------------------------\n","|mean loss epoch    16|mean l 1.484682|vppl 4.413561\n","-------------------------------------------------------\n","| epoch  17 | lr 0.01 | loss 3.109622 | ppl 22.412568\n","| epoch  17 | lr 0.01 | loss 1.583931 | ppl 4.874077\n","| epoch  17 | lr 0.01 | loss 1.553068 | ppl 4.725946\n","| epoch  17 | lr 0.01 | loss 1.522603 | ppl 4.584141\n","| epoch  17 | lr 0.01 | loss 1.525652 | ppl 4.598142\n","| epoch  17 | lr 0.01 | loss 1.518553 | ppl 4.565614\n","| epoch  17 | lr 0.01 | loss 1.518733 | ppl 4.566438\n","| epoch  17 | lr 0.01 | loss 1.519139 | ppl 4.568288\n","-------------------------------------------------------\n","|mean loss epoch    17|mean l 1.509271|vppl 4.523434\n","-------------------------------------------------------\n","| epoch  18 | lr 0.01 | loss 3.171559 | ppl 23.844634\n","| epoch  18 | lr 0.01 | loss 1.588285 | ppl 4.895348\n","| epoch  18 | lr 0.01 | loss 1.530271 | ppl 4.619428\n","| epoch  18 | lr 0.01 | loss 1.522877 | ppl 4.585396\n","| epoch  18 | lr 0.01 | loss 1.514184 | ppl 4.545708\n","| epoch  18 | lr 0.01 | loss 1.509728 | ppl 4.525498\n","| epoch  18 | lr 0.01 | loss 1.509291 | ppl 4.523524\n","| epoch  18 | lr 0.01 | loss 1.512071 | ppl 4.536115\n","-------------------------------------------------------\n","|mean loss epoch    18|mean l 1.503940|vppl 4.499382\n","-------------------------------------------------------\n","| epoch  19 | lr 0.00 | loss 2.934598 | ppl 18.813936\n","| epoch  19 | lr 0.00 | loss 1.543759 | ppl 4.682155\n","| epoch  19 | lr 0.00 | loss 1.526101 | ppl 4.600205\n","| epoch  19 | lr 0.00 | loss 1.511021 | ppl 4.531353\n","| epoch  19 | lr 0.00 | loss 1.507240 | ppl 4.514253\n","| epoch  19 | lr 0.00 | loss 1.501238 | ppl 4.487243\n","| epoch  19 | lr 0.00 | loss 1.500172 | ppl 4.482460\n","| epoch  19 | lr 0.00 | loss 1.496105 | ppl 4.464265\n","-------------------------------------------------------\n","|mean loss epoch    19|mean l 1.485393|vppl 4.416700\n","-------------------------------------------------------\n","| epoch  20 | lr 0.00 | loss 3.024236 | ppl 20.578281\n","| epoch  20 | lr 0.00 | loss 1.546749 | ppl 4.696178\n","| epoch  20 | lr 0.00 | loss 1.533866 | ppl 4.636066\n","| epoch  20 | lr 0.00 | loss 1.509416 | ppl 4.524086\n","| epoch  20 | lr 0.00 | loss 1.500584 | ppl 4.484306\n","| epoch  20 | lr 0.00 | loss 1.501621 | ppl 4.488960\n","| epoch  20 | lr 0.00 | loss 1.497670 | ppl 4.471260\n","| epoch  20 | lr 0.00 | loss 1.499067 | ppl 4.477511\n","-------------------------------------------------------\n","|mean loss epoch    20|mean l 1.488374|vppl 4.429885\n","-------------------------------------------------------\n"]}]},{"cell_type":"code","source":["best_model"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"--uEKdkpe561","executionInfo":{"status":"ok","timestamp":1661588814260,"user_tz":-180,"elapsed":27,"user":{"displayName":"Vixen","userId":"12443801616054990678"}},"outputId":"c326f27c-aac9-4144-e2d1-d2277c05c715"},"execution_count":40,"outputs":[{"output_type":"execute_result","data":{"text/plain":["TransformerModel(\n","  (pos_encoder): PositionalEncoding(\n","    (dropout): Dropout(p=0.5, inplace=False)\n","  )\n","  (transformer_encoder): TransformerEncoder(\n","    (layers): ModuleList(\n","      (0): TransformerEncoderLayer(\n","        (self_attn): MultiheadAttention(\n","          (out_proj): NonDynamicallyQuantizableLinear(in_features=200, out_features=200, bias=True)\n","        )\n","        (linear1): Linear(in_features=200, out_features=200, bias=True)\n","        (dropout): Dropout(p=0.5, inplace=False)\n","        (linear2): Linear(in_features=200, out_features=200, bias=True)\n","        (norm1): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n","        (norm2): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n","        (dropout1): Dropout(p=0.5, inplace=False)\n","        (dropout2): Dropout(p=0.5, inplace=False)\n","      )\n","      (1): TransformerEncoderLayer(\n","        (self_attn): MultiheadAttention(\n","          (out_proj): NonDynamicallyQuantizableLinear(in_features=200, out_features=200, bias=True)\n","        )\n","        (linear1): Linear(in_features=200, out_features=200, bias=True)\n","        (dropout): Dropout(p=0.5, inplace=False)\n","        (linear2): Linear(in_features=200, out_features=200, bias=True)\n","        (norm1): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n","        (norm2): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n","        (dropout1): Dropout(p=0.5, inplace=False)\n","        (dropout2): Dropout(p=0.5, inplace=False)\n","      )\n","    )\n","  )\n","  (encoder): Embedding(7050, 200)\n","  (decoder): Linear(in_features=200, out_features=16041, bias=True)\n",")"]},"metadata":{},"execution_count":40}]},{"cell_type":"code","source":["def translate_to_spain(idx):\n","    print('Предложение на английском :', ' '.join(pairs[idx][0])) \n","    print('Предложение на испанском  :', ' '.join(pairs[idx][1])) \n","\n","    sent_np_in = sent_to_torch(pairs[idx][0], input_lang)\n","    output     = best_model(tr.tensor(sent_np_in,  dtype=tr.long, device=device))\n","\n","    print('Перевод seq2seq           :', \n","          ' '.join([output_lang.index2word[i.item()] \n","                    for i in output[0].data.topk(1)[1] if i > 3])) "],"metadata":{"id":"hE5n6URwfAdt","executionInfo":{"status":"ok","timestamp":1661588814260,"user_tz":-180,"elapsed":18,"user":{"displayName":"Vixen","userId":"12443801616054990678"}}},"execution_count":41,"outputs":[]},{"cell_type":"code","source":["translate_to_spain(72422)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CYUuCTDOfFl_","executionInfo":{"status":"ok","timestamp":1661588814260,"user_tz":-180,"elapsed":18,"user":{"displayName":"Vixen","userId":"12443801616054990678"}},"outputId":"4321927e-d779-49ee-998d-d2421b71bacb"},"execution_count":42,"outputs":[{"output_type":"stream","name":"stdout","text":["Предложение на английском : he is close to sixty\n","Предложение на испанском  : ему около шестидесяти\n","Перевод seq2seq           : он\n"]}]},{"cell_type":"code","source":["translate_to_spain(11111)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"clRaHz_BfHaP","executionInfo":{"status":"ok","timestamp":1661588814261,"user_tz":-180,"elapsed":16,"user":{"displayName":"Vixen","userId":"12443801616054990678"}},"outputId":"bba263bd-0945-446d-eced-c43d80658c94"},"execution_count":43,"outputs":[{"output_type":"stream","name":"stdout","text":["Предложение на английском : tom is normal\n","Предложение на испанском  : том обычныи\n","Перевод seq2seq           : том\n"]}]},{"cell_type":"code","source":["translate_to_spain(54863)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lEXS5RSufPJw","executionInfo":{"status":"ok","timestamp":1661588814261,"user_tz":-180,"elapsed":14,"user":{"displayName":"Vixen","userId":"12443801616054990678"}},"outputId":"54e07a08-8be5-48d9-f9b9-d0f38f545b68"},"execution_count":44,"outputs":[{"output_type":"stream","name":"stdout","text":["Предложение на английском : we re very curious\n","Предложение на испанском  : мы очень любопытны\n","Перевод seq2seq           : мы очень\n"]}]}]}