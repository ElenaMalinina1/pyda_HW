{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"RNN 3.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"mount_file_id":"1Zkje-ZFOZN017D2m6MvpegkhEHv8SSF8","authorship_tag":"ABX9TyNZfWhIKbyToFKbjtIV/hWf"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["# Задание\n","1. Возьмите англо-русскую пару фраз (https://www.manythings.org/anki/)\n","2. Обучите на них seq2seq по аналогии с занятием. Оцените полученное качество\n","3. Попробуйте добавить +1 рекуррентный в encoder и decoder\n","4. Попробуйте заменить GRU ячейки на lstm-ячейки\n","5. Оцените качество во всех случаях"],"metadata":{"id":"y87ibU_ixhnM"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"1VevoiNUxc0_","executionInfo":{"status":"ok","timestamp":1659181334994,"user_tz":-180,"elapsed":598,"user":{"displayName":"Vixen","userId":"12443801616054990678"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"60a53845-d458-4f93-97d1-228dcc6a20af"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda')"]},"metadata":{},"execution_count":1}],"source":["from io import open\n","import unicodedata\n","import string\n","import re\n","import random\n","\n","import torch\n","import torch.nn as nn\n","from torch import optim\n","import torch.nn.functional as F\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')  \n","device"]},{"cell_type":"code","source":["SOS_token = 0\n","EOS_token = 1\n","\n","class Lang:\n","    def __init__(self, name):\n","        self.name = name\n","        self.word2index = {}\n","        self.word2count = {}\n","        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n","        self.n_words = 2  # Count SOS and EOS\n","\n","    def addSentence(self, sentence):\n","        for word in sentence.split(' '):\n","            self.addWord(word)\n","\n","    def addWord(self, word):\n","        if word not in self.word2index:\n","            self.word2index[word] = self.n_words\n","            self.word2count[word] = 1\n","            self.index2word[self.n_words] = word\n","            self.n_words += 1\n","        else:\n","            self.word2count[word] += 1"],"metadata":{"id":"MaPIUhNg0JiG","executionInfo":{"status":"ok","timestamp":1659181334994,"user_tz":-180,"elapsed":4,"user":{"displayName":"Vixen","userId":"12443801616054990678"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# Turn a Unicode string to plain ASCII, thanks to\n","# http://stackoverflow.com/a/518232/2809427\n","def unicodeToAscii(s):\n","    return ''.join(\n","        c for c in unicodedata.normalize('NFD', s)\n","        if unicodedata.category(c) != 'Mn'\n","    )\n","\n","# Lowercase, trim, and remove non-letter characters\n","def normalizeString(s):\n","    s = unicodeToAscii(s.lower().strip())\n","    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n","    s = re.sub(r\"([,\\'])\", r\"\", s)\n","    return s"],"metadata":{"id":"hsjp79DP0KQZ","executionInfo":{"status":"ok","timestamp":1659181334995,"user_tz":-180,"elapsed":4,"user":{"displayName":"Vixen","userId":"12443801616054990678"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["def readLangs(lang1, lang2, reverse=False):\n","    print(\"Reading lines...\")\n","\n","    # Read the file and split into lines\n","    lines = open('/content/drive/MyDrive/HW/Deep learning/Data/rus.txt', encoding='utf-8').\\\n","        read().strip().split('\\n')\n","\n","    # Split every line into pairs and normalize\n","    pairs = [[normalizeString(s) for s in l.split('\\t')[0:2]] for l in lines]\n","\n","    # Reverse pairs, make Lang instances\n","    if reverse:\n","        pairs = [list(reversed(p)) for p in pairs]\n","        input_lang = Lang(lang2)\n","        output_lang = Lang(lang1)\n","    else:\n","        input_lang = Lang(lang1)\n","        output_lang = Lang(lang2)\n","\n","    return input_lang, output_lang, pairs"],"metadata":{"id":"SWD5zl5N0Q_v","executionInfo":{"status":"ok","timestamp":1659181334995,"user_tz":-180,"elapsed":4,"user":{"displayName":"Vixen","userId":"12443801616054990678"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["MAX_LENGTH = 10\n","\n","eng_prefixes = (\n","    \"i am \", \"i m \",\n","    \"he is\", \"he s \",\n","    \"she is\", \"she s\",\n","    \"you are\", \"you re \",\n","    \"we are\", \"we re \",\n","    \"they are\", \"they re \"\n",")\n","\n","def filterPair(p):\n","    return len(p[0].split(' ')) < MAX_LENGTH and \\\n","        len(p[1].split(' ')) < MAX_LENGTH and \\\n","        p[1].startswith(eng_prefixes)\n","\n","def filterPairs(pairs):\n","    return [pair for pair in pairs if filterPair(pair)]"],"metadata":{"id":"kkhtnn0N00Z3","executionInfo":{"status":"ok","timestamp":1659181335501,"user_tz":-180,"elapsed":510,"user":{"displayName":"Vixen","userId":"12443801616054990678"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["def prepareData(lang1, lang2, reverse=False):\n","    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n","    print(\"Read %s sentence pairs\" % len(pairs))\n","    pairs = filterPairs(pairs)\n","    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n","    print(\"Counting words...\")\n","    for pair in pairs:\n","        input_lang.addSentence(pair[0])\n","        output_lang.addSentence(pair[1])\n","    print(\"Counted words:\")\n","    print(input_lang.name, input_lang.n_words)\n","    print(output_lang.name, output_lang.n_words)\n","    return input_lang, output_lang, pairs"],"metadata":{"id":"MxAbMkRm06Mw","executionInfo":{"status":"ok","timestamp":1659181335502,"user_tz":-180,"elapsed":21,"user":{"displayName":"Vixen","userId":"12443801616054990678"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["## Encoder RNN"],"metadata":{"id":"Xi93vUTT1Myh"}},{"cell_type":"code","source":["class EncoderRNN(nn.Module):\n","    def __init__(self, input_size, hidden_size, n_layers=1):\n","        super(EncoderRNN, self).__init__()\n","        self.hidden_size = hidden_size\n","        self.n_layers = n_layers\n","\n","        self.embedding = nn.Embedding(input_size, hidden_size)\n","        self.gru = nn.GRU(hidden_size, hidden_size, num_layers=n_layers)\n","\n","    def forward(self, input, hidden):\n","        embedded = self.embedding(input).view(1, 1, -1)\n","        output = embedded\n","        output, hidden = self.gru(output, hidden)\n","        return output, hidden\n","\n","    def initHidden(self):\n","        return torch.zeros(self.n_layers*1, 1, self.hidden_size, device=device)"],"metadata":{"id":"H8SiW1U_FHpF","executionInfo":{"status":"ok","timestamp":1659181335502,"user_tz":-180,"elapsed":18,"user":{"displayName":"Vixen","userId":"12443801616054990678"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["## Encoder_RNN_LSTM"],"metadata":{"id":"6NT6edfd1oA2"}},{"cell_type":"code","source":["class Encoder_RNN_LSTM(nn.Module):\n","    def __init__(self, input_size, hidden_size, n_layers=1):\n","        super(Encoder_RNN_LSTM, self).__init__()\n","        self.hidden_size = hidden_size\n","        self.n_layers = n_layers\n","\n","        self.embedding = nn.Embedding(input_size, hidden_size)\n","        self.lstm = nn.LSTM(hidden_size, hidden_size, num_layers=n_layers)\n","\n","    def forward(self, input, hidden, cell):\n","        embedded = self.embedding(input).view(1, 1, -1)\n","        output, (hidden, cell) = self.lstm(embedded, (hidden, cell))\n","        return output, (hidden, cell)\n","\n","    def initHidden(self):\n","        return [torch.zeros(self.n_layers*1, 1, self.hidden_size, device=device),\n","                torch.zeros(self.n_layers*1, 1, self.hidden_size, device=device)]"],"metadata":{"id":"1ctgLam41sMr","executionInfo":{"status":"ok","timestamp":1659181335503,"user_tz":-180,"elapsed":17,"user":{"displayName":"Vixen","userId":"12443801616054990678"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["## Decoder RNN"],"metadata":{"id":"BHa5HX0I1VvM"}},{"cell_type":"code","source":["class DecoderRNN(nn.Module):\n","    def __init__(self, hidden_size, output_size, n_layers=1):\n","        super(DecoderRNN, self).__init__()\n","        self.hidden_size = hidden_size\n","\n","        self.embedding = nn.Embedding(output_size, hidden_size)\n","        self.gru = nn.GRU(hidden_size, hidden_size, num_layers=n_layers)\n","        self.out = nn.Linear(hidden_size, output_size)\n","        self.softmax = nn.LogSoftmax(dim=1)\n","\n","    def forward(self, input, hidden):\n","        output = self.embedding(input).view(1, 1, -1)\n","        output = F.relu(output)\n","        output, hidden = self.gru(output, hidden)\n","        output = self.softmax(self.out(output[0]))\n","        return output, hidden\n","\n","    def initHidden(self):\n","        return torch.zeros(1, 1, self.hidden_size, device=device)"],"metadata":{"id":"dSkTT6wa1Prx","executionInfo":{"status":"ok","timestamp":1659181335503,"user_tz":-180,"elapsed":17,"user":{"displayName":"Vixen","userId":"12443801616054990678"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["##Decoder_RNN_LSTM"],"metadata":{"id":"BXYP4XM74EmL"}},{"cell_type":"code","source":["class Decoder_RNN_LSTM(nn.Module):\n","    def __init__(self, hidden_size, output_size, n_layers=1):\n","        super(Decoder_RNN_LSTM, self).__init__()\n","        self.hidden_size = hidden_size\n","\n","        self.embedding = nn.Embedding(output_size, hidden_size)\n","        self.lstm = nn.LSTM(hidden_size, hidden_size, num_layers=n_layers)\n","        self.out = nn.Linear(hidden_size, output_size)\n","        self.softmax = nn.LogSoftmax(dim=1)\n","\n","    def forward(self, input, hidden, cell):\n","        output = self.embedding(input).view(1, 1, -1)\n","        output, (hidden, cell) = self.lstm(output, (hidden, cell))\n","        output = self.softmax(self.out(output.squeeze(0)))\n","        return output, (hidden, cell)\n","\n","    def initHidden(self):\n","        return [torch.zeros(self.n_layers*1, 1, self.hidden_size, device=device),\n","                torch.zeros(self.n_layers*1, 1, self.hidden_size, device=device)]"],"metadata":{"id":"pPQ03Bqe4R0f","executionInfo":{"status":"ok","timestamp":1659181335503,"user_tz":-180,"elapsed":16,"user":{"displayName":"Vixen","userId":"12443801616054990678"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["def indexesFromSentence(lang, sentence):\n","    return [lang.word2index[word] for word in sentence.split(' ')]\n","\n","def tensorFromSentence(lang, sentence):\n","    indexes = indexesFromSentence(lang, sentence)\n","    indexes.append(EOS_token)\n","    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n","\n","def tensorsFromPair(pair):\n","    input_tensor = tensorFromSentence(input_lang, pair[0])\n","    target_tensor = tensorFromSentence(output_lang, pair[1])\n","    return (input_tensor, target_tensor)"],"metadata":{"id":"7a4GCudC5o4F","executionInfo":{"status":"ok","timestamp":1659181335504,"user_tz":-180,"elapsed":17,"user":{"displayName":"Vixen","userId":"12443801616054990678"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["teacher_forcing_ratio = 0.5\n","\n","def train(model_name, input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n","    encoder_hidden = encoder.initHidden()\n","\n","    encoder_optimizer.zero_grad()\n","    decoder_optimizer.zero_grad()\n","\n","    input_length = input_tensor.size(0)\n","    target_length = target_tensor.size(0)\n","\n","    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n","\n","    loss = 0\n","\n","    if model_name == 'gru':\n","        for ei in range(input_length):\n","            encoder_output, encoder_hidden = encoder(\n","                input_tensor[ei], encoder_hidden)\n","            encoder_outputs[ei] = encoder_output[0, 0]\n","    else: # lstm\n","        for ei in range(input_length):\n","            encoder_output, (encoder_hidden[0], encoder_hidden[1]) = encoder(\n","                input_tensor[ei].unsqueeze(0), encoder_hidden[0], encoder_hidden[1])\n","            encoder_outputs[ei] = encoder_output.squeeze()\n","\n","    decoder_input = torch.tensor([[SOS_token]], device=device)\n","\n","    decoder_hidden = encoder_hidden\n","\n","    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n","\n","    if use_teacher_forcing:\n","        # Teacher forcing: Feed the target as the next input\n","        for di in range(target_length):\n","            if model_name == 'gru':\n","                decoder_output, decoder_hidden = decoder(\n","                decoder_input, decoder_hidden)\n","            else:\n","                decoder_output, (decoder_hidden[0], decoder_hidden[1]) = decoder(\n","                decoder_input, decoder_hidden[0], decoder_hidden[1])\n","\n","            loss += criterion(decoder_output, target_tensor[di])\n","            decoder_input = target_tensor[di]  # Teacher forcing\n","\n","    else:\n","        # Without teacher forcing: use its own predictions as the next input\n","        for di in range(target_length):\n","            if model_name == 'gru':\n","                decoder_output, decoder_hidden = decoder(\n","                    decoder_input, decoder_hidden)\n","            else:\n","                decoder_output, (decoder_hidden[0], decoder_hidden[1]) = decoder(\n","                    decoder_input, decoder_hidden[0], decoder_hidden[1])\n","            topv, topi = decoder_output.topk(1)\n","            decoder_input = topi.squeeze().detach()  # detach from history as input\n","\n","            loss += criterion(decoder_output, target_tensor[di])\n","            if decoder_input.item() == EOS_token:\n","                break\n","\n","    loss.backward()\n","\n","    encoder_optimizer.step()\n","    decoder_optimizer.step()\n","\n","    return loss.item() / target_length"],"metadata":{"id":"ZESLJ8Iw5pKi","executionInfo":{"status":"ok","timestamp":1659181335505,"user_tz":-180,"elapsed":18,"user":{"displayName":"Vixen","userId":"12443801616054990678"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["import time\n","import math\n","\n","def asMinutes(s):\n","    m = math.floor(s / 60)\n","    s -= m * 60\n","    return '%dm %ds' % (m, s)\n","\n","def timeSince(since, percent):\n","    now = time.time()\n","    s = now - since\n","    es = s / (percent)\n","    rs = es - s\n","    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"],"metadata":{"id":"dWDw4jj08KAG","executionInfo":{"status":"ok","timestamp":1659181335505,"user_tz":-180,"elapsed":17,"user":{"displayName":"Vixen","userId":"12443801616054990678"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["def trainIters(model_name, encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n","    start = time.time()\n","    plot_losses = []\n","    print_loss_total = 0  # Reset every print_every\n","    plot_loss_total = 0  # Reset every plot_every\n","\n","    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n","    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n","    training_pairs = [tensorsFromPair(random.choice(pairs))\n","                      for i in range(n_iters)]\n","    criterion = nn.NLLLoss()\n","\n","    for iter in range(1, n_iters + 1):\n","        training_pair = training_pairs[iter - 1]\n","        input_tensor = training_pair[0]\n","        target_tensor = training_pair[1]\n","\n","        loss = train(model_name, input_tensor, target_tensor, encoder,\n","                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n","        print_loss_total += loss\n","        plot_loss_total += loss\n","\n","        if iter % print_every == 0:\n","            print_loss_avg = print_loss_total / print_every\n","            print_loss_total = 0\n","            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n","                                         iter, iter / n_iters * 100, print_loss_avg))\n","\n","        if iter % plot_every == 0:\n","            plot_loss_avg = plot_loss_total / plot_every\n","            plot_losses.append(plot_loss_avg)\n","            plot_loss_total = 0\n","\n","    showPlot(plot_losses)"],"metadata":{"id":"ppD187O08MVw","executionInfo":{"status":"ok","timestamp":1659181335505,"user_tz":-180,"elapsed":17,"user":{"displayName":"Vixen","userId":"12443801616054990678"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["%matplotlib inline\n","import matplotlib.pyplot as plt\n","plt.switch_backend('agg')\n","import matplotlib.ticker as ticker\n","import numpy as np\n","\n","def showPlot(points):\n","    plt.figure()\n","    fig, ax = plt.subplots()\n","    # this locator puts ticks at regular intervals\n","    loc = ticker.MultipleLocator(base=0.2)\n","    ax.yaxis.set_major_locator(loc)\n","    plt.plot(points)"],"metadata":{"id":"jXrrsMoq8Y4i","executionInfo":{"status":"ok","timestamp":1659181335506,"user_tz":-180,"elapsed":18,"user":{"displayName":"Vixen","userId":"12443801616054990678"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["def evaluate(model_name, encoder, decoder, sentence, max_length=MAX_LENGTH):\n","    with torch.no_grad():\n","        input_tensor = tensorFromSentence(input_lang, sentence)\n","        input_length = input_tensor.size()[0]\n","        encoder_hidden = encoder.initHidden()\n","\n","        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n","\n","        if model_name == 'gru':\n","            for ei in range(input_length):\n","                encoder_output, encoder_hidden = encoder(\n","                    input_tensor[ei], encoder_hidden)\n","                encoder_outputs[ei] = encoder_output[0, 0]\n","        else:  # lstm\n","            for ei in range(input_length):\n","                encoder_output, (encoder_hidden[0], encoder_hidden[1]) = encoder(\n","                    input_tensor[ei].unsqueeze(0), encoder_hidden[0], encoder_hidden[1])\n","                encoder_outputs[ei] = encoder_output.squeeze()\n","\n","        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n","\n","        decoder_hidden = encoder_hidden\n","\n","        decoded_words = []\n","\n","        for di in range(max_length):\n","            if model_name == 'gru':\n","                decoder_output, decoder_hidden = decoder(\n","                    decoder_input, decoder_hidden)\n","            else:\n","                decoder_output, (decoder_hidden[0], decoder_hidden[1]) = decoder(\n","                    decoder_input, decoder_hidden[0], decoder_hidden[1])\n","\n","            topv, topi = decoder_output.data.topk(1)\n","\n","            if topi.item() == EOS_token:\n","                decoded_words.append('<EOS>')\n","                break\n","            else:\n","                decoded_words.append(output_lang.index2word[topi.item()])\n","\n","            decoder_input = topi.squeeze().detach()\n","\n","        return decoded_words"],"metadata":{"id":"_WMx4GZl8Z6P","executionInfo":{"status":"ok","timestamp":1659181335506,"user_tz":-180,"elapsed":17,"user":{"displayName":"Vixen","userId":"12443801616054990678"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["def evaluateRandomly(model_name, encoder, decoder, n=10):\n","    lucky = 0\n","    for i in range(n):\n","        pair = random.choice(pairs)\n","        print('>', pair[0])\n","        print('=', pair[1])\n","        output_words = evaluate(model_name, encoder, decoder, pair[0])\n","        output_sentence = ' '.join(output_words)\n","        print('<', output_sentence)\n","\n","        if output_sentence[0:len(pair[1])] == pair[1]:\n","            lucky += 1\n","        print('')\n","\n","    print(f'Dullness: {lucky*100/n} %')"],"metadata":{"id":"aTP9aOCU-rMN","executionInfo":{"status":"ok","timestamp":1659181335506,"user_tz":-180,"elapsed":17,"user":{"displayName":"Vixen","userId":"12443801616054990678"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["input_lang, output_lang, pairs = prepareData('eng', 'rus', True)\n","print(random.choice(pairs))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZadjvudhAtba","executionInfo":{"status":"ok","timestamp":1659181354871,"user_tz":-180,"elapsed":19382,"user":{"displayName":"Vixen","userId":"12443801616054990678"}},"outputId":"1aa705e5-a625-4696-9d0e-cf622dbf2d28"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Reading lines...\n","Read 444587 sentence pairs\n","Trimmed to 4185 sentence pairs\n","Counting words...\n","Counted words:\n","rus 3728\n","eng 2003\n","['он деиствует от своего имени .', 'he is acting on his own behalf .']\n"]}]},{"cell_type":"markdown","source":["###  Обучите на них seq2seq по аналогии с занятием. Оцените полученное качество"],"metadata":{"id":"RIJqorFmC48m"}},{"cell_type":"code","source":["hidden_size = 256\n","\n","encoder_1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n","decoder_1 = DecoderRNN(hidden_size, output_lang.n_words).to(device)\n","trainIters('gru', encoder_1, decoder_1, 75000, print_every=5000)\n","evaluateRandomly('gru', encoder_1, decoder_1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3Z75u3GIBAtS","outputId":"c88858ed-77e8-4e1e-87c6-d565da6908a6","executionInfo":{"status":"ok","timestamp":1659181979688,"user_tz":-180,"elapsed":624394,"user":{"displayName":"Vixen","userId":"12443801616054990678"}}},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["0m 44s (- 10m 24s) (5000 6%) 3.0664\n","1m 24s (- 9m 10s) (10000 13%) 2.4733\n","2m 5s (- 8m 22s) (15000 20%) 1.9988\n","2m 45s (- 7m 35s) (20000 26%) 1.5631\n","3m 27s (- 6m 55s) (25000 33%) 1.2030\n","4m 8s (- 6m 12s) (30000 40%) 0.9450\n","4m 49s (- 5m 31s) (35000 46%) 0.6885\n","5m 30s (- 4m 49s) (40000 53%) 0.5307\n","6m 12s (- 4m 8s) (45000 60%) 0.3860\n","6m 53s (- 3m 26s) (50000 66%) 0.2687\n","7m 35s (- 2m 45s) (55000 73%) 0.1931\n","8m 16s (- 2m 4s) (60000 80%) 0.1346\n","8m 58s (- 1m 22s) (65000 86%) 0.0997\n","9m 39s (- 0m 41s) (70000 93%) 0.0764\n","10m 21s (- 0m 0s) (75000 100%) 0.0638\n","> он лучше всех подходит для этого проекта .\n","= he is the best for this project .\n","< he is the best for this project . <EOS>\n","\n","> я больше не уставшии .\n","= i am no longer tired .\n","< i am no longer tired . <EOS>\n","\n","> я убежден в твоеи невиновности .\n","= i am convinced of your innocence .\n","< i am convinced of your innocence . <EOS>\n","\n","> я знаю об этом факте .\n","= i am aware of the fact .\n","< i am aware of the fact . <EOS>\n","\n","> мы с ним сегодня увидимся .\n","= i am going to see him today .\n","< i am going to see him today . <EOS>\n","\n","> он готовится к контрольнои .\n","= he is preparing for the test .\n","< he is preparing for the test . <EOS>\n","\n","> ты очень элегантен .\n","= you are very elegant .\n","< you are very elegant . <EOS>\n","\n","> она выглядит счастливои .\n","= she seems happy .\n","< she seems happy . <EOS>\n","\n","> она юна .\n","= she is young .\n","< she is young . <EOS>\n","\n","> она постоянно пишет письма .\n","= she is constantly writing letters .\n","< she is constantly writing letters . <EOS>\n","\n","Dullness: 100.0 %\n"]}]},{"cell_type":"markdown","source":["### Попробуйте добавить +1 рекуррентный в encoder и decoder"],"metadata":{"id":"uq7KbibLCzMU"}},{"cell_type":"code","source":["hidden_size = 256\n","\n","encoder_1 = EncoderRNN(input_lang.n_words, hidden_size, n_layers=2).to(device)\n","decoder_1 = DecoderRNN(hidden_size, output_lang.n_words, n_layers=2).to(device)\n","trainIters('gru', encoder_1, decoder_1, 75000, print_every=5000)\n","evaluateRandomly('gru', encoder_1, decoder_1)"],"metadata":{"id":"aDkIMdRrCD-u","executionInfo":{"status":"ok","timestamp":1659182711575,"user_tz":-180,"elapsed":731899,"user":{"displayName":"Vixen","userId":"12443801616054990678"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"28cff432-28bd-47ab-e6f9-82725c13f555"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["0m 50s (- 11m 51s) (5000 6%) 3.0880\n","1m 38s (- 10m 42s) (10000 13%) 2.5703\n","2m 26s (- 9m 44s) (15000 20%) 2.1822\n","3m 14s (- 8m 54s) (20000 26%) 1.7649\n","4m 1s (- 8m 3s) (25000 33%) 1.4073\n","4m 50s (- 7m 16s) (30000 40%) 1.0905\n","5m 39s (- 6m 28s) (35000 46%) 0.8315\n","6m 28s (- 5m 39s) (40000 53%) 0.5976\n","7m 17s (- 4m 51s) (45000 60%) 0.4433\n","8m 5s (- 4m 2s) (50000 66%) 0.3057\n","8m 55s (- 3m 14s) (55000 73%) 0.2193\n","9m 43s (- 2m 25s) (60000 80%) 0.1524\n","10m 32s (- 1m 37s) (65000 86%) 0.1073\n","11m 23s (- 0m 48s) (70000 93%) 0.0940\n","12m 11s (- 0m 0s) (75000 100%) 0.0665\n","> он всего лишь ребенок .\n","= he is but a child .\n","< he is just a child . <EOS>\n","\n","> она улыбнулась взмахнув рукои .\n","= she smiled waving her hand .\n","< she smiled waving her hand . <EOS>\n","\n","> ты не наш друг .\n","= you are not our friend .\n","< you are not our friend . <EOS>\n","\n","> ты мои лучшии друг .\n","= you are my best friend .\n","< you are my best friend . <EOS>\n","\n","> он всегда занят как пчела .\n","= he is always as busy as a bee .\n","< he is always as busy as a bee . <EOS>\n","\n","> боюсь ваш план не будет работать .\n","= i am afraid your plan will not work .\n","< i am afraid your plan will not work . <EOS>\n","\n","> ты не наша подруга .\n","= you are not our friend .\n","< you are not our friend . <EOS>\n","\n","> ты не приглашена .\n","= you arent invited .\n","< you arent invited . <EOS>\n","\n","> он слишком устал чтобы учиться .\n","= he is too tired to study .\n","< he is too tired to study . <EOS>\n","\n","> вы ведь не шпион да ?\n","= you arent a spy are you ?\n","< you arent a spy are you ? <EOS>\n","\n","Dullness: 90.0 %\n"]}]},{"cell_type":"markdown","source":["### Попробуйте заменить GRU ячейки на lstm-ячейки"],"metadata":{"id":"c_LHF2K-C-oh"}},{"cell_type":"code","source":["hidden_size = 256\n","\n","encoder_1 = Encoder_RNN_LSTM(input_lang.n_words, hidden_size).to(device)\n","decoder_1 = Decoder_RNN_LSTM(hidden_size, output_lang.n_words).to(device)\n","trainIters('lstm', encoder_1, decoder_1, 75000, print_every=5000)\n","evaluateRandomly('lstm', encoder_1, decoder_1)"],"metadata":{"id":"OMoshGfhCr53","executionInfo":{"status":"ok","timestamp":1659183328439,"user_tz":-180,"elapsed":616872,"user":{"displayName":"Vixen","userId":"12443801616054990678"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"7757a65a-bd01-4933-cf4b-f7391894e954"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["0m 43s (- 10m 6s) (5000 6%) 3.2292\n","1m 22s (- 8m 56s) (10000 13%) 2.6760\n","2m 3s (- 8m 14s) (15000 20%) 2.4335\n","2m 43s (- 7m 30s) (20000 26%) 2.1165\n","3m 24s (- 6m 49s) (25000 33%) 1.7897\n","4m 5s (- 6m 8s) (30000 40%) 1.5141\n","4m 46s (- 5m 27s) (35000 46%) 1.2372\n","5m 27s (- 4m 46s) (40000 53%) 1.0232\n","6m 8s (- 4m 5s) (45000 60%) 0.7895\n","6m 50s (- 3m 25s) (50000 66%) 0.6315\n","7m 30s (- 2m 43s) (55000 73%) 0.4887\n","8m 12s (- 2m 3s) (60000 80%) 0.3780\n","8m 53s (- 1m 22s) (65000 86%) 0.2793\n","9m 35s (- 0m 41s) (70000 93%) 0.1908\n","10m 16s (- 0m 0s) (75000 100%) 0.1542\n","> я порядочныи человек .\n","= i am an honest person .\n","< i am an honest person . <EOS>\n","\n","> я одинокии человек .\n","= i am a lonely man .\n","< i am a lonely man . <EOS>\n","\n","> ты слишком молод чтобы путешествовать в одиночку .\n","= you are too young to travel alone .\n","< you are too young to travel alone . <EOS>\n","\n","> он добр к окружающим .\n","= he is kind to those around him .\n","< he is kind to those around him . <EOS>\n","\n","> она строга к ним .\n","= she is hard on them .\n","< she is hard on them . <EOS>\n","\n","> он ужинает .\n","= he is having dinner .\n","< he is having dinner . <EOS>\n","\n","> он силен как никогда .\n","= he is stronger than ever .\n","< he is stronger than ever . <EOS>\n","\n","> мы измеряем глубину реки .\n","= we are measuring the depth of the river .\n","< we are measuring the depth of the river . <EOS>\n","\n","> я убежден .\n","= i am sure .\n","< i am sure . <EOS>\n","\n","> он мои самыи младшии брат .\n","= he is my youngest brother .\n","< he is my youngest brother . <EOS>\n","\n","Dullness: 100.0 %\n"]}]},{"cell_type":"markdown","source":["GRU на 2 слоях оказался хуже, чем LSTM"],"metadata":{"id":"apqLVWqlDOmn"}}]}